{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2957fca",
   "metadata": {},
   "source": [
    "Part #1 - Some Global Functions\n",
    "\n",
    "Function A - Importing Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805c0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = Name of the excel file\n",
    "# s = Sheet Name within the excel file\n",
    "# r = Range of data which needs to be imported\n",
    "# d = Data object that needs to be sent while exporting back\n",
    "\n",
    "def import_excel(n,s,r):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    data = sheet.range(r).value\n",
    "    return data \n",
    "\n",
    "def export_excel(n,s,r,d):\n",
    "    import xlwings as xw\n",
    "    wb = xw.Book(n)\n",
    "    sheet = wb.sheets[s]\n",
    "    sheet.range(r).value = d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101efc31",
   "metadata": {},
   "source": [
    "Function B - MFBD Holiday Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7dff5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = Date on which operation is to be performed\n",
    "#cal1 = Country of Calendar 1, For USA pass argument US\n",
    "#cal2 = Country of Calendar 2, For India pass argument IN .. This is an optional argument\n",
    "# At present this function suports a max of 2 calendars only for MFBD\n",
    "\n",
    "def mfbd(dt,cal1, cal2=\"NIL\"):\n",
    "    from datetime import date\n",
    "    from datetime import timedelta\n",
    "    import holidays\n",
    "    direction = 1\n",
    "    calendar1 = holidays.country_holidays(cal1)\n",
    "    if cal2 == \"NIL\":\n",
    "        while dt.weekday() > 4 or dt in calendar1:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    else:\n",
    "        calendar2 = holidays.country_holidays(cal2)\n",
    "        while dt.weekday() > 4 or dt in calendar1 or dt in calendar2:\n",
    "            if dt.month == (dt+timedelta(days=1)).month - 1:\n",
    "                direction = -1\n",
    "            dt = dt + timedelta(days=1)*direction \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044e5b8",
   "metadata": {},
   "source": [
    "Function C - Curve Bootstrapping Function\n",
    "\n",
    "Gives you a set of Discount Factors and Zero Rates for a given IRS curve (USD in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "deb2b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapir(data,i=-1,p=1):\n",
    "    import pandas as pd\n",
    "    from datetime import date,timedelta\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns=['Tenor','Unit','Rate']\n",
    "    #Set Pricing Date\n",
    "    PDate = date(2025,5,19)  #You can set it to desired pricing date\n",
    "    SDate = mfbd(PDate + timedelta(days=2),'US') #Calculating the Spot Start Date\n",
    "    \n",
    "    i = int(i)\n",
    "    if i>-1:\n",
    "        df.iat[i,2]=df.iat[i,2]+0.0001*p\n",
    "    # Compute the Maturity Dates and Payment Dates for each tenor (supports weeks and months only as of now)\n",
    "    # Assuming 2 Days Payment Delay for Standard SOFR Swaps as per current market convention\n",
    "    for index,row in df.iterrows():\n",
    "        if df.at[index,'Unit']== \"w\":\n",
    "            df.at[index,'MDate']=mfbd(SDate+timedelta(weeks=df.at[index,'Tenor']),'US')\n",
    "        else:\n",
    "            df.at[index,'MDate']=mfbd(SDate+relativedelta(months=df.at[index,'Tenor']),'US')\n",
    "        df.at[index,'PDate']=mfbd(df.at[index,'MDate']+timedelta(days=2),'US')\n",
    "    df['DC']=(df['PDate']-SDate)/timedelta(days=1)/360\n",
    "    df['Days']=(df['PDate']-SDate)/timedelta(days=1)\n",
    "    df['DF']=1/(1+df['Rate']*df['DC'])\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f6d5e",
   "metadata": {},
   "source": [
    "Function D - Compare DFs against an alternate benchmark like Bloomberg\n",
    "\n",
    "![title][def]\n",
    "\n",
    "[def]: SOFRBBG.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f01295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df):\n",
    "    import pandas as pd\n",
    "    bbgdata = import_excel('Market Data.xlsx','USDIRSShort','h3:h17')\n",
    "    bbg = pd.DataFrame(bbgdata)\n",
    "    bbg.columns=['BBGDF']\n",
    "    comp = df[['Tenor','Unit','PDate','DF']]\n",
    "    comp['BBGDF'] = bbg['BBGDF'] #Need to find a better method to append columns as this is giving a warning \n",
    "    comp['DF Gap(bps)']=(comp['BBGDF']-comp['DF'])*10000/comp['BBGDF']\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefe1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tenor Unit       PDate        DF     BBGDF  DF Gap(bps)\n",
      "0     1.0    w  2025-05-30  0.998924  0.998924    -0.000714\n",
      "1     2.0    w  2025-06-06  0.998086  0.998086     0.000717\n",
      "2     3.0    w  2025-06-13  0.997249  0.997249     0.000693\n",
      "3     1.0    m  2025-06-25  0.995815  0.995815     0.003759\n",
      "4     2.0    m  2025-07-23  0.992482  0.992482    -0.002813\n",
      "5     3.0    m  2025-08-25  0.988606  0.988840     2.362592\n",
      "6     4.0    m  2025-09-24  0.985123  0.985120    -0.026390\n",
      "7     5.0    m  2025-10-23  0.981846  0.981841    -0.049781\n",
      "8     6.0    m  2025-11-24  0.978317  0.978423     1.084186\n",
      "9     7.0    m  2025-12-24  0.975103  0.975094    -0.092741\n",
      "10    8.0    m  2026-01-23  0.971971  0.971959    -0.122421\n",
      "11    9.0    m  2026-02-25  0.968613  0.968599    -0.147335\n",
      "12   10.0    m  2026-03-25  0.965816  0.965799    -0.171059\n",
      "13   11.0    m  2026-04-23  0.962992  0.962973    -0.198750\n",
      "14   12.0    m  2026-05-26  0.959802  0.960094     3.043136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5g/4br4skc15dlb750j33xn06rh0000gn/T/ipykernel_768/2177254367.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comp['BBGDF'] = bbg['BBGDF'] #Need to find a better method to append columns as this is giving a warning\n",
      "/var/folders/5g/4br4skc15dlb750j33xn06rh0000gn/T/ipykernel_768/2177254367.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comp['DF Gap(bps)']=(comp['BBGDF']-comp['DF'])*10000/comp['BBGDF']\n"
     ]
    }
   ],
   "source": [
    "data = import_excel('Market Data.xlsx','USDIRSShort','A3:C17')\n",
    "df=bootstrapir(data)\n",
    "compare(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7626f",
   "metadata": {},
   "source": [
    "We see that the Discount Factors Generated are very close except for the 3 months and 12 months point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd18651",
   "metadata": {},
   "source": [
    "Function E - FX Curve Bootstrap Function \n",
    "\n",
    "This takes as an input short dated fx spot + swap points (You can do it using outrights as well but either approach works)\n",
    "\n",
    "Please note that INR Onshore short term fx swap curve trades on the month end instead of rollings which is the general convention globally and hence I have chosen the most liquid points for building the curves. \n",
    "\n",
    "Using the rolling points may be more convenient but you do end up losing a bit of precision which is not desirable (However, the NDF points are more liquid on rolling basis in line with international convention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fc66c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapfx(data,usdf,i=-1,p=1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date,timedelta, datetime, time\n",
    "    df=pd.DataFrame(data)\n",
    "    df.columns=['Date','Points']\n",
    "    spotrate=85.50 #I have taken the liberty of putting the spot rate here in the code directly but you can import it from excel / any other source\n",
    "    df['OR']=spotrate + df['Points']/100\n",
    "    #Set Pricing Date\n",
    "    PDate = date(2025,5,19)  #You can set it to desired pricing date\n",
    "    SDate = mfbd(PDate + timedelta(days=2),'US','IN') #Calculating the Spot Start Date\n",
    "    #Add 1 as Discount Factor for Spot Date in the Discount Factors Data Frame for US Rates \n",
    "    usdf.loc[-1] = [0.0,\"w\",0.0,SDate,SDate,0,0,1.00000]\n",
    "    usdf.index = usdf.index+1\n",
    "    usdf = usdf.sort_index()\n",
    "    #Copy equivalent USD DFs into the FX based DF table\n",
    "    #This will require us to interpolate and we are creating a float column as we cant interpolate on dates directly\n",
    "    MyTime = time(0,0,0)\n",
    "    df['Days']=(df['Date']-datetime.combine(SDate,MyTime))/timedelta(days=1)\n",
    "    usdf['PDate'] = usdf['PDate'].astype(\"datetime64[ns]\")\n",
    "    usdf['Days']=(usdf['PDate']-datetime.combine(SDate,MyTime))/timedelta(days=1)\n",
    "    df['USDF']=np.interp(df['Days'],usdf['Days'],usdf['DF'])\n",
    "    df['INRDF']=df['USDF']*spotrate/df['OR']\n",
    "    df['INRYld']=(1/df['INRDF']-1)*365/df['Days']\n",
    "    #This step overwrites the DFs and the Outrights with perturbed values if any\n",
    "    i = int(i)\n",
    "    if i>-1:\n",
    "        df.iat[i,6]=df.iat[i,6]+0.0001*p\n",
    "    df['INRDF']=1/(1+df['INRYld']*df['Days']/365)\n",
    "    df['OR']=spotrate *df['USDF']/df['INRDF']\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de8c14",
   "metadata": {},
   "source": [
    "Please note that the forwards data is upto 373 days and the USD IRS data is for a slightly shorter tenor creating a potential issue if you try to price trades accurately between those 2 days (3 days in this example between day 370 and 373. I have just ignored this for the moment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38168ad",
   "metadata": {},
   "source": [
    "Function F - This will price a portfolio of short dated fx outright forwards and compute their NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fa5f08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable i controls the US Curve points perturb\n",
    "#Variable j controls the INR FX Curve perturb\n",
    "#gd is the variable which controls the generate dependent curve behaviour\n",
    "\n",
    "def priceFX(i=-1,j=-1,p=1,gd=1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date,timedelta, datetime, time\n",
    "    spotrate=85.50\n",
    "    #Generate US Curve\n",
    "    data = import_excel('Market Data.xlsx','USDIRSShort','A3:C17')\n",
    "    usdf=bootstrapir(data,i,p)\n",
    "    usdforig=bootstrapir(data)\n",
    "    #Generate INR FX Curve\n",
    "    data = import_excel('Market Data.xlsx','INRFX','A3:B15')\n",
    "    if gd==1:\n",
    "        inrdf=bootstrapfx(data,usdf,j,p)\n",
    "    else:\n",
    "        inrdf=bootstrapfx(data,usdforig,j,p)\n",
    "\n",
    "    data = import_excel('TradePrice.xlsx','ShortINRFX','B3:D4') #Import market data\n",
    "    fxport = pd.DataFrame(data)\n",
    "    fxport.columns=['Notional','Date','Rate']\n",
    "    usdf=usdf.sort_index()\n",
    "    PDate = date(2025,5,19)  #You can set it to desired pricing date\n",
    "    SDate = mfbd(PDate + timedelta(days=2),'US','IN') #Calculating the Spot Start Date\n",
    "    MyTime = time(0,0,0)\n",
    "    fxport['Days']=(fxport['Date']-datetime.combine(SDate,MyTime))/timedelta(days=1)\n",
    "    fxport['MktRate']=np.interp(fxport['Days'],inrdf['Days'],inrdf['OR'])\n",
    "    fxport['INRDF']=np.interp(fxport['Days'],inrdf['Days'],inrdf['INRDF'])\n",
    "    fxport['USDDF']=np.interp(fxport['Days'],usdf['Days'],usdf['DF'])\n",
    "    fxport['INRNPV']=fxport['Notional']*(fxport['MktRate']-fxport['Rate'])*fxport['INRDF']\n",
    "    fxport['INRLegPV']=fxport['Notional']*fxport['Rate']*-1*fxport['INRDF']\n",
    "    fxport['USDLegPV']=fxport['Notional']*fxport['USDDF']\n",
    "    #print(usdf)\n",
    "    #print(inrdf)\n",
    "    #print(fxport)\n",
    "    #print(fxport['INRLegPV'].sum())\n",
    "    #return fxport['INRNPV'].sum()\n",
    "    return fxport['INRLegPV'].sum()+fxport['USDLegPV'].sum()*spotrate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e6c2443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Portfolio NPV :  4162199.1\n"
     ]
    }
   ],
   "source": [
    "NPV = priceFX()\n",
    "print(\"Current Portfolio NPV : \",round(NPV,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0bf549",
   "metadata": {},
   "source": [
    "Now lets price and generate currency wise sensitivity for this portfolio of trades\n",
    "\n",
    "Approach #1 - Without generate dependents - Most traders in India tend to use this. There is no right or wrong answer between this approach and with generate dependents. A more detailed explanation is out of scope as only someone who has truly run long and short fx books would understand this. I will try and see if I can elaborate further later. Reach out to me directly on pushkargondane@gmail.com if you would like to chat about it. \n",
    "\n",
    "In a nutshell the difference related to if a curve is regenerated if its base or underlying curve is perturbed (In this case INR curve is derived out of the USD Curve and everytime we bump the USD Curve, the INR curve is not getting bumped subsequently aka not getting regenerated => No generation of  dependent curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6077f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Portfolio NPV :  45921068.1\n",
      "USD Bucket  1 : 0.0\n",
      "USD Bucket  2 : 0.0\n",
      "USD Bucket  3 : 0.0\n",
      "USD Bucket  4 : 0.0\n",
      "USD Bucket  5 : 0.0\n",
      "USD Bucket  6 : 0.0\n",
      "USD Bucket  7 : 0.0\n",
      "USD Bucket  8 : 0.0\n",
      "USD Bucket  9 : 0.0\n",
      "USD Bucket  10 : 0.0\n",
      "USD Bucket  11 : -41982.1\n",
      "USD Bucket  12 : -15123.97\n",
      "USD Bucket  13 : 0.0\n",
      "USD Bucket  14 : -58473.52\n",
      "USD Bucket  15 : -17169.98\n",
      "Total USD Dv01 :  -132749.57\n",
      "INR Bucket  1 : 0.0\n",
      "INR Bucket  2 : 0.0\n",
      "INR Bucket  3 : 0.0\n",
      "INR Bucket  4 : 0.0\n",
      "INR Bucket  5 : 0.0\n",
      "INR Bucket  6 : 0.0\n",
      "INR Bucket  7 : 0.0\n",
      "INR Bucket  8 : 0.0\n",
      "INR Bucket  9 : 52055.17\n",
      "INR Bucket  10 : 2121.35\n",
      "INR Bucket  11 : 0.0\n",
      "INR Bucket  12 : 70960.44\n",
      "INR Bucket  13 : 0.0\n",
      "Total INR Dv01 :  125136.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NPV = priceFX()\n",
    "print(\"Current Portfolio NPV : \",round(NPV,2))\n",
    "\n",
    "#Lets start with USD Dv01 buckets first\n",
    "Dv01 = 0\n",
    "for i in range(15):\n",
    "    NewPV = priceFX(i,-1,1,0)\n",
    "    print(\"USD Bucket \",i+1 ,\":\" , round(NewPV - NPV,2))\n",
    "\n",
    "    Dv01 = Dv01 + NewPV - NPV\n",
    "print (\"Total USD Dv01 : \", round(Dv01,2))\n",
    "\n",
    "#Lets now move to INR Dv01 buckets\n",
    "Dv01 = 0\n",
    "for i in range(13):\n",
    "    NewPV = priceFX(-1,i)\n",
    "    print(\"INR Bucket \",i+1 ,\":\" , round(NewPV - NPV,2))\n",
    "\n",
    "    Dv01 = Dv01 + NewPV - NPV\n",
    "print (\"Total INR Dv01 : \", round(Dv01,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f3dee",
   "metadata": {},
   "source": [
    "Approach #2 - This is the proper generate dependents algorithm wherein the USD Curve is generated and any bumps in the USD Curve create a bump in the curves dependent on them aka INR curve in this case. Note that the USD Sensitivity is not completely 0 across the board in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1fc1d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Portfolio NPV :  45921068.1\n",
      "USD Bucket  1 : 0.0\n",
      "USD Bucket  2 : 0.0\n",
      "USD Bucket  3 : 0.0\n",
      "USD Bucket  4 : 0.0\n",
      "USD Bucket  5 : 0.0\n",
      "USD Bucket  6 : 0.0\n",
      "USD Bucket  7 : 0.0\n",
      "USD Bucket  8 : 0.0\n",
      "USD Bucket  9 : 0.0\n",
      "USD Bucket  10 : 0.0\n",
      "USD Bucket  11 : -933.0\n",
      "USD Bucket  12 : -668.21\n",
      "USD Bucket  13 : 169.44\n",
      "USD Bucket  14 : -1784.53\n",
      "USD Bucket  15 : -524.0\n",
      "Total USD Dv01 :  -3740.3\n",
      "INR Bucket  1 : 0.0\n",
      "INR Bucket  2 : 0.0\n",
      "INR Bucket  3 : 0.0\n",
      "INR Bucket  4 : 0.0\n",
      "INR Bucket  5 : 0.0\n",
      "INR Bucket  6 : 0.0\n",
      "INR Bucket  7 : 0.0\n",
      "INR Bucket  8 : 0.0\n",
      "INR Bucket  9 : 52055.17\n",
      "INR Bucket  10 : 2121.35\n",
      "INR Bucket  11 : 0.0\n",
      "INR Bucket  12 : 70960.44\n",
      "INR Bucket  13 : 0.0\n",
      "Total INR Dv01 :  125136.96\n"
     ]
    }
   ],
   "source": [
    "NPV = priceFX()\n",
    "print(\"Current Portfolio NPV : \",round(NPV,2))\n",
    "\n",
    "#Lets start with USD Dv01 first\n",
    "Dv01 = 0\n",
    "for i in range(15):\n",
    "    NewPV = priceFX(i)\n",
    "    print(\"USD Bucket \",i+1 ,\":\" , round(NewPV - NPV,2))\n",
    "\n",
    "    Dv01 = Dv01 + NewPV - NPV\n",
    "print (\"Total USD Dv01 : \", round(Dv01,2))\n",
    "\n",
    "#Lets start with USD Dv01 first\n",
    "Dv01 = 0\n",
    "for i in range(13):\n",
    "    NewPV = priceFX(-1,i)\n",
    "    print(\"INR Bucket \",i+1 ,\":\" , round(NewPV - NPV,2))\n",
    "\n",
    "    Dv01 = Dv01 + NewPV - NPV\n",
    "print (\"Total INR Dv01 : \", round(Dv01,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32482cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae282dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
